{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geV7I-gXxuL6"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "1)Core Idea :\n",
        "Instead of just voting, we train another model to learn how to combine models.\n",
        "\n",
        "So it‚Äôs like:\n",
        "Level 1 ‚Üí Multiple different models\n",
        "Level 2 ‚Üí One meta-model that learns from their outputs\n",
        "\n",
        "\n",
        "2)Why Stacking is Powerful ?\n",
        "Because:\n",
        "Some models are good in linear regions\n",
        "Some are good in non-linear regions\n",
        "Some overfit\n",
        "Some underfit\n",
        "Stacking learns where each model performs well.\n",
        "\n",
        "\n",
        "3)When To Use What?\n",
        "Dataset small ‚Üí Voting\n",
        "Dataset medium/complex ‚Üí Stacking\n",
        "High variance models ‚Üí Bagging\n",
        "High bias models ‚Üí Boosting\n",
        "\n",
        "Q)\n",
        "1)what is data leakage?\n",
        "2)Why do we use cross-validation in stacking?\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split ,KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC"
      ],
      "metadata": {
        "id": "NMG8TSyGyW1l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "Tz4_i5ga0Eu-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "üß† Why We Need Cross-Validation in Stacking?\n",
        "If you train base models on full training data and use their predictions to train meta-model on the same data ‚Üí data leakage.\n",
        "\n",
        "So we:\n",
        "Use K-Fold\n",
        "Generate out-of-fold predictions\n",
        "Train meta-model on those\n",
        "This is how real stacking works.\n",
        "'''"
      ],
      "metadata": {
        "id": "zdp_u7YQfXRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_models = [\n",
        "    LogisticRegression(max_iter = 5000),\n",
        "    DecisionTreeClassifier(),\n",
        "    SVC(probability = True)\n",
        "]\n",
        "\n",
        "kf = KFold(n_splits = 5 ,shuffle = True ,random_state = 42)\n",
        "n_train ,n_test = X_train.shape[0] ,X_test.shape[0]\n",
        "n_models = len(base_models)\n",
        "\n",
        "meta_train = np.zeros((n_train ,n_models))\n",
        "meta_test = np.zeros((n_test ,n_models))"
      ],
      "metadata": {
        "id": "zql5pdJd0LKx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i ,model in enumerate(base_models):\n",
        "    meta_test_fold = np.zeros((n_test ,5)) #5 Splits\n",
        "\n",
        "    for j ,(train_idx ,val_idx) in enumerate(kf.split(X_train)):\n",
        "        X_tr ,X_val = X_train[train_idx] ,X_train[val_idx]\n",
        "        y_tr ,y_val = y_train[train_idx] ,y_train[val_idx]\n",
        "\n",
        "        model.fit(X_tr ,y_tr)\n",
        "\n",
        "        meta_train[val_idx ,i] = model.predict(X_val)\n",
        "\n",
        "        meta_test_fold[: ,j] = model.predict(X_test)\n",
        "\n",
        "    meta_test[: ,i] = meta_test_fold.mean(axis = 1)"
      ],
      "metadata": {
        "id": "RfSoDW_u02pE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_model = LogisticRegression(max_iter = 5000)\n",
        "meta_model.fit(meta_train ,y_train)\n",
        "\n",
        "final_predictions = meta_model.predict(meta_test)\n",
        "print(\"Stacking Accuracy:\",\n",
        "      accuracy_score(y_test ,final_predictions))"
      ],
      "metadata": {
        "id": "8aGBl15h02XO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "310c3e9e-a1c4-421b-ebd4-75c5c8184f59"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for model in base_models:\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    print(type(model).__name__,\n",
        "          \"Accuracy:\",\n",
        "          accuracy_score(y_test, preds))"
      ],
      "metadata": {
        "id": "xtsECgCF02Tp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41fc91a7-e5d5-44b6-afd0-c85cc6cff125"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression Accuracy: 0.956140350877193\n",
            "DecisionTreeClassifier Accuracy: 0.9473684210526315\n",
            "SVC Accuracy: 0.9473684210526315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "üß† Step 1: What Is K-Fold?\n",
        "Imagine you have 100 samples.\n",
        "Instead of training once, we split data into parts.\n",
        "If we use 5-Fold, we divide data into 5 equal parts:\n",
        "\n",
        "Part 1\n",
        "Part 2\n",
        "Part 3\n",
        "Part 4\n",
        "Part 5\n",
        "\n",
        "Each part has 20 samples.\n",
        "üîÅ How K-Fold Works\n",
        "We train 5 times:\n",
        "\n",
        "Round 1\n",
        "Train on: 2,3,4,5\n",
        "Test on: 1\n",
        "\n",
        "Round 2\n",
        "Train on: 1,3,4,5\n",
        "Test on: 2\n",
        "\n",
        "Round 3\n",
        "Train on: 1,2,4,5\n",
        "Test on: 3\n",
        "\n",
        "‚Ä¶and so on.\n",
        "\n",
        "Every part gets a chance to be the \"test set\".\n",
        "That‚Äôs K-Fold cross-validation.\n",
        "\n",
        "üéØ Why Do We Do This?\n",
        "Because training once might depend too much on how we split data.\n",
        "\n",
        "K-Fold:\n",
        "‚úî Uses all data for training\n",
        "‚úî Uses all data for testing\n",
        "‚úî Gives more reliable performance\n",
        "\n",
        "üß† Now Let‚Äôs Connect It to Stacking\n",
        "Suppose we are doing stacking.\n",
        "\n",
        "We have:\n",
        "Base Model 1\n",
        "Base Model 2\n",
        "Meta Model\n",
        "\n",
        "If we train base models on full training data, then predict on same data:\n",
        "That prediction is too perfect.\n",
        "The model already saw the answers.\n",
        "\n",
        "That‚Äôs cheating.\n",
        "üí° So What Do We Do Instead?\n",
        "\n",
        "We use K-Fold.\n",
        "Let‚Äôs say 5-fold again.\n",
        "\n",
        "For each fold:\n",
        "Train base model on 4 parts\n",
        "Predict on the 1 part it didn‚Äôt see\n",
        "Now for every sample, we get a prediction from a model that never trained on it.\n",
        "\n",
        "That prediction is called:\n",
        "üëâ Out-of-Fold (OOF) prediction\n",
        "\n",
        "üî• Very Small Example\n",
        "Data:\n",
        "Sample 1\n",
        "Sample 2\n",
        "Sample 3\n",
        "Sample 4\n",
        "Sample 5\n",
        "\n",
        "\n",
        "2-Fold:\n",
        "Split into:\n",
        "\n",
        "Fold A ‚Üí 1,2,3\n",
        "Fold B ‚Üí 4,5\n",
        "\n",
        "First round:\n",
        "Train on B ‚Üí Predict on A\n",
        "\n",
        "Second round:\n",
        "Train on A ‚Üí Predict on B\n",
        "\n",
        "Now:\n",
        "Every sample has a prediction\n",
        "From a model that didn‚Äôt see it.\n",
        "\n",
        "That‚Äôs what we use to train the meta-model.\n",
        "\n",
        "üß† Simple Analogy\n",
        "Think of it like this:\n",
        "If you ask your friend to solve a problem:\n",
        "If they already saw the answer ‚Üí their guess is fake good\n",
        "If they didn‚Äôt see the answer ‚Üí their guess is honest\n",
        "\n",
        "Stacking needs honest guesses.\n",
        "K-Fold gives honest guesses.\n",
        "\n",
        "üöÄ Why This Matters\n",
        "\n",
        "If you skip K-Fold:\n",
        "\n",
        "Meta-model learns from fake-perfect predictions\n",
        "‚Üí Overfitting\n",
        "‚Üí Bad real-world performance\n",
        "\n",
        "If you use K-Fold:\n",
        "\n",
        "Meta-model learns from realistic predictions\n",
        "‚Üí Better generalization\n",
        "'''"
      ],
      "metadata": {
        "id": "mRXp_8ALdPJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inbuilt Stacking\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "stack = StackingClassifier(\n",
        "    estimators=[\n",
        "        ('lr', LogisticRegression(max_iter=5000)),\n",
        "        ('tree', DecisionTreeClassifier()),\n",
        "        ('svm', SVC(probability=True))\n",
        "    ],\n",
        "    final_estimator=LogisticRegression()\n",
        ")\n",
        "\n",
        "stack.fit(X_train, y_train)\n",
        "print(\"Stacking Accuracy:\",\n",
        "      accuracy_score(y_test, stack.predict(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4UKHkLD00oT6",
        "outputId": "35545a23-9590-4397-d84f-ab4d9ea1b7a0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    }
  ]
}